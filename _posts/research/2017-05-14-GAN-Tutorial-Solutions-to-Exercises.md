---
title: GAN介绍 - 练习题答案
layout: post
mathjax: true
categories: [research, gan-tutorial]
---

[制作中]

## 8.1 最优的判别器策略

我们的目标是在函数空间最小化

![Equation 23](/images/201705/10/eq23.jpg)

也就是直接优化$D(x)$$。

我们开始通过假定$$p_{data}$$和$$p_{model}$$全局是非零。 如果我们不做此假设， 那么在训练过程中有些点将永远不会被访问到， 并且会出现不被定义的行为。

为了最小化关于$$D$$的$$J^{D}$$，我们给出一个针对$$D（x）$$的导数(通过固定$$G$$)， 并且设此导数为零：

![Equation 24](/images/201705/10/eq24.jpg)

通过解此方程， 我们得到

![Equation 25](/images/201705/10/eq25.jpg)

估计此比值是一个很重要的近似机制，使用GAN， 图35展示了此过程。

![Figure 35](/images/201705/10/fig35.jpg)

图35： 展示关于判别器如何估计密度的比值。 在这个例子中， 为了简化起见， 我们假设z和x是一维的。
从z到x（蓝色的箭头所指）的映射是不均匀的（non-uniform）因此p_{model}(x)（绿色的曲线）在z的值密度更大时会比较大。
判别器（蓝色虚线）估计数据密度（黑点）和模型密度与数据的之和的比值。
判别器输出大的地方， 模型密度就比较低， 并且判别器输出比较小的地方， 模型密度比较高。
生成器可以学习来产生更好的模型密度通过跟随判别器的上升； 每一个G(z)的值应该慢慢移动朝着提高D(G(z))的方向。
此图来此Goodfellow et al. (2014b).

[关于详细解法，请参考Goodfellow的2014年的文章中的证明]

！[Figure addfig01](/images/201705/10/addfig01.jpg)

## 8.2 游戏的梯度下降

价值函数

![Equation 26](/images/201705/10/eq23.jpg)

可能是最简单的带鞍点的连续函数。
通过观察此价值函数在三个维度上， 很好理解这个游戏， 如图36。

三个维度视角，清晰的展示了，有一个saddle point 在x=y=0。
这是此游戏的平衡点。 我们也可能通过解方程的导数等于零，来得到这个点。

不是每一个鞍点都是平衡点； 我们需要一个对一个玩家的参数进行极小的扰动，而不减少此玩家的损失。
这个游戏中的鞍点满足这个要求。
**有些时候，是病态的平衡，当将另一个玩家的参数固定以后， 此玩家的价值数据将是一个常量。**

为了求解这个梯度下降的轨迹， 我们使用偏导数， 然后发现，

![Equation 27](/images/201705/10/eq27.jpg)

对28求微分，我们得到

![Equation 29](/images/201705/10/eq29.jpg)

这个形式的微分方程有正曲线作为解决方案的基函数。 解系数对应边界条件，我们得到

![Equation 30](/images/201705/10/eq30.jpg)


## 8.3 GAN框架中的最大似然

