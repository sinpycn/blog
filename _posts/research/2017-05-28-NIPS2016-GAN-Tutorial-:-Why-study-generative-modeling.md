---
layout: post
mathjax: true
---

人们可能会问为什么要学习生成式模型， 特别是生成式模型只能产生数据而不是提供对密度函数的估计。 
例如在图像的应用， 这类模型好像仅仅是提供更多的图像， 但是我们的世界并不缺少图像。

这里列举了以下几个学习生成式模型的原因：
1. 生成式模型的训练和采样是一个对表达和操作高维概率分布问题的非常好的测试。 高维的概率分布问题是一个很重要的问题，在数学和工程领域有很广泛的应用。 
2. 生成式模型可以以多种方式被应用到增强学习中（reinforcement learning）。 

   增强学习可以被分为两大类， model-based和model-free。
   model-based算法包含一个生成式模型。 基于时间序列的生成式模型可以用来模拟可能的未来， 这类模型可以以多种方式来做规划（planning）和增强学习。
   用来做规划的生成式模型， 可以通过使用当前状态以及目标对象可能发生的假设的行为来学习预测未来状态的条件分布。
   <span style="color:red">目标对象可以使用不同的潜在的行为来与模型进行交互，并选择让模型的预测结果倾向于期望状态的行为。</span>
   可以参考模型例子， Finn et al. (2016a); 用于规划学习的模型， Finn and Levine (2016).

   另一方式是，将产生式模型用于对假设环境的增强学习， 这样错误行为不会造成实际的损失。
   <span style="color:red">生成式模型也可以用于指导探险者通过跟踪 以前不同的状态被访问，或者不同的行为被尝试频率。
   生成式模型，特别是GAN，也可以用于inverse refinforcement learning。 </span>
   详细的将在Section5.6进一步解释

3. 生成式模型可以使用missing data来训练，并且可以提供对丢失数据的预测。 一个丢失数据的例子是semi-supervised learning， 这种情况下很多或者绝大部分的数据都丢失了。 流行的深度模型都需要大量的标定数据来进行训练才能有比较好的推广能力。 Semi-supervised learning是一种减少标定数据的策略。 此方法可以使用大量的非标定数据来提高模型的推广能力，通常非标定数据是很容易获取的。 生成式模型，特别是GAN可能让Semi-supervised learning表现相当好。 将在5.4章进一步介绍。

4. 生成式模型，和GAN， 使机器学习可以用于多模输出（multi-modal output）。 有很多任务，一个输入可能对应多个正确的输出， 每一个输出都是正确的（比如说翻译任务）。 传统的基于平均的机器学习模型，比如说最小化期望输出和预测输出的均方误差（MSE）方法，无法训练此类有多个正确输出的模型。 一个例子是如图3描述的预测视频的下一帧。

   ![Figure 3](/images/201704/28/fig03.png)

   图3： Lotter et al. (2015) 提供一个对多模数据建模的很好的演示。 在此例子中， 模型被训练来预测视频的下一帧。 视频展示了一个计算机程序来表达头部移动的3D模型。 左边图像是一个希望模型来预测的视频的真实的一帧图像。 中间的图像是，是使用MSE来训练的模型的来预测的结果。 MSE使用真实的下一帧图像与预测的下一帧图像来计算。 这个模型被强制为只能选择一个下一帧的正确答案。 因为下一帧有很多的可能性， 这些可能的答案会有些细微的位置上的差别， 单一的答案选择让模型针对这些不同的图像取平均值。 从而导致了耳朵消失，眼睛变得模糊。 通过使用GAN loss, 右边的图像可以理解下一帧可以有很多可能的输出，并且每一个都是尖锐（sharp），并且看起来比较真实，细致的图片。 

5. 最后， 很多任务本身需要根据分布来产生数据。 这种例子有:

   5.1 单一图片超高分辨率： 这个任务是使用一个低分辨率图片产生高分辨率图片。 需要生成式模型是因为需要模型加入比原始输入图像更多的信息。 针对一个低分辨率的图像来说对应多种的可能的高分辨率图像。 模型需要根据概率分布从可能的图像中选出一个。 通过对所有可能的样本做平均化处理会使图像变模糊。 如图4.

  ![Figure 4](/images/201704/28/fig04.png)
  图4： Ledig et al. (2016) 给出了一个非常好的单张图片的高分辨率效果， 此结果显示了使用生成式模型根据多模的分布来生产真实样本的优势。 最左边的图像是原始的高分辨率图像， 然后通过downsample制作低分辨率图像。 然后使用不同的方法来试图恢复高分辨率图像。 Bicubic方法是一种插补方法，没有使用对训练数据的统计信息。 SRResNet是一个使用MSE训练的神经网络。 SRGAN是一种基于GAN的神经网络， SRGAN的提高是因为它可以理解有多种正确的答案，而不是对多种正确的答案做平均化处理，从而得到单一的最好结果。
  
  5.2 艺术创作任务。 最近的两个项目都演示了生成式模型，特别是GAN，可以被用来制作交互式程序，通过给出想像的粗略的场景来辅助用户创建真实的图像。 参考图5，6。
  
  ![Figure 5](/images/201704/28/fig05.jpg)
  
  图5： Zhu et al. (2016) 开发了一个交互程序被称为 interactive GAN (iGAN). 用户可以画一个粗糙的草图， 然后iGAN使用GAN来尝试最相似的真实图片。 在这个例子中， 当用户粗糙的画了一些绿色线， iGAN生成了长满草的区域， 当用户画了一个黑色的三角形， iGAN就生成了一个细致的山。 艺术创作的应用是学习使用生成式模型生产图像的一个原因。 iGAN的视频可以看以下的URL：https://www.youtube.com/watch?v=9c4z6YsBGQ0
  
  ![Figure 6](/images/201704/28/fig06.jpg)
  
  图6： Brock et al. (2016) 开发了introspective adversarial networks (IAN) 内省对抗网络。 用户对图像做一个简单的修改， 比如将一个区域涂成黑色从而想加上黑色的头发， IAN可以将这种简单的涂抹转换为用户的期望的图片。 对图像进行真实的修改是学习生成式模型的一个理由。 视频请参考：https://www.youtube.com/watch?v=FDELBFSeqQs
  
  5.3 Image-to-image 转换应用可以将航空图像转换为地图， 或者将素描转换为图像。 各种惊喜的应用还会不断的被开发出来， 参考图7.
    
  ![Figure 7](/images/201704/28/fig07.jpg)
  
  图7： Isola et al. (2016) 制作了包含很多种转换的图到图的转换应用： 将卫星图像转为地图； 将素描桩位真实的照片等等。 因为这个转换过程中每一个输入都对应多个输出， 有必要使用生成式建模来正确的训练模型。 特别的， Isola et al. (2016) 使用了GAN。 图到图的转换的给出了很多例子， 这些例子让我们看到一个创新的设计可以帮助我们发现很多意想不到的生成式网络的应用。 未来肯定还会有更多的应用被发现。
