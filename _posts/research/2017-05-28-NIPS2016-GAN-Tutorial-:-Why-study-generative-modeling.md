---
layout: post
mathjax: true
---

人们可能会问为什么要学习生成式模型， 特别是生成式模型只能产生数据而不是提供对密度函数的估计。 
例如在图像的应用， 这类模型好像仅仅是提供更多的图像， 但是我们的世界并不缺少图像。

这里列举了以下几个学习生成式模型的原因：
1. 生成式模型的训练和采样是一个对表达和操作高维概率分布问题的非常好的测试。 高维的概率分布问题是一个很重要的问题，在数学和工程领域有很广泛的应用。 
2. 生成式模型可以以多种方式被应用到增强学习中（reinforcement learning）。 

   增强学习可以被分为两大类， model-based和model-free。
   model-based算法包含一个生成式模型。 基于时间序列的生成式模型可以用来模拟可能的未来， 这类模型可以以多种方式来做规划（planning）和增强学习。
   用来做规划的生成式模型， 可以通过使用当前状态以及目标对象可能发生的假设的行为来学习预测未来状态的条件分布。
   <span style="color:red">目标对象可以使用不同的潜在的行为来与模型进行交互，并选择让模型的预测结果倾向于期望状态的行为。</span>
   可以参考模型例子， Finn et al. (2016a); 用于规划学习的模型， Finn and Levine (2016).

   另一方式是，将产生式模型用于对假设环境的增强学习， 这样错误行为不会造成实际的损失。
   <span style="color:red">生成式模型也可以用于指导探险者通过跟踪 以前不同的状态被访问，或者不同的行为被尝试频率。
   生成式模型，特别是GAN，也可以用于inverse refinforcement learning。 </span>
   详细的将在Section5.6进一步解释

3. 生成式模型可以使用missing data来训练，并且可以提供对丢失数据的预测。 一个丢失数据的例子是semi-supervised learning， 这种情况下很多或者绝大部分的数据都丢失了。 流行的深度模型都需要大量的标定数据来进行训练才能有比较好的推广能力。 Semi-supervised learning是一种减少标定数据的策略。 此方法可以使用大量的非标定数据来提高模型的推广能力，通常非标定数据是很容易获取的。 生成式模型，特别是GAN可能让Semi-supervised learning表现相当好。 将在5.4章进一步介绍。

4. 生成式模型，和GAN， 使机器学习可以用于多模输出（multi-modal output）。 有很多任务，一个输入可能对应多个正确的输出， 每一个输出都是正确的（比如说翻译任务）。 传统的基于平均的机器学习模型，比如说最小化期望输出和预测输出的均方误差（MSE）方法，无法训练此类有多个正确输出的模型。 一个例子是如图3描述的预测视频的下一帧。

   ![Figure 3](/images/201704/28/fig03.png)

   图3： Lotter et al. (2015) 提供一个对多模数据建模的很好的演示。 在此例子中， 模型被训练来预测视频的下一帧。 视频展示了一个计算机程序来表达头部移动的3D模型。 左边图像是一个希望模型来预测的视频的真实的一帧图像。 中间的图像是，是使用MSE来训练的模型的来预测的结果。 MSE使用真实的下一帧图像与预测的下一帧图像来计算。 这个模型被强制为只能选择一个下一帧的正确答案。 因为下一帧有很多的可能性， 这些可能的答案会有些细微的位置上的差别， 单一的答案选择让模型针对这些不同的图像取平均值。 从而导致了耳朵消失，眼睛变得模糊。 通过使用GAN loss, 右边的图像可以理解下一帧可以有很多可能的输出，并且每一个都是尖锐（sharp），并且看起来比较真实，细致的图片。 

5. 最后， 很多任务本身需要根据分布来产生数据。 这种例子有

   5.1 单一图片超高分辨率： 这个任务是使用一个低分辨率图片产生高分辨率图片。 需要生成式模型是因为需要模型加入比原始输入图像更多的信息。 有很多的

  ![Figure 4](/images/201704/28/fig04.png)
  ![Figure 5](/images/201704/28/fig05.jpg)
  ![Figure 6](/images/201704/28/fig06.jpg)
  ![Figure 7](/images/201704/28/fig07.jpg)
