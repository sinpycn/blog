---
title: GAN介绍 - GAN是如何工作的?
layout: post
mathjax: true
---

[制作中]
我们已经了解了GAN与其他生成模型的区别，下面我们将学习GAN是如何工作的。

## 3.1 GAN framework

GAN的基本思想是两个玩家共同玩一个游戏。 其中一个叫生成器。 生成器根据训练数据的分布来生成样本。 另一个玩家是判别器。 判别器用来判别样本的真伪。
判别器使用传统的监督学习的方法，将输入分类为真和假两个类。 生成器被优化来试图欺骗判别器。
举个例子来说， 生成器类似于假币制造者，他试图制作假币， 判别器类似于警察， 他试图判别真币和假币。 
为了在游戏中取得成功， 造假者必须学习制造能够以假乱真的假币， 意味着生成器必须学习生成与训练数据有同样分布的样本。
图12展示了这个过程。

![Figure 12](/images/201705/03/fig12.jpg)

图12： GAN设计为两个对抗的玩家在同一个游戏中互相对抗。 玩家被描述为由一组参数组成的可微函数。 通常情况下，这些函数都使用深度神经网络。
这个游戏可以被展开为两个场景。 第一个场景， 随机的从训练数据集中采样$$x$$, 采样的数据作为判别器$$D$$的输入。 判别器的目的是预测样本是真实样本的概率， 此判决假设输入的样本一半是真样本，另一半是伪样本。 在此场景中， 判别器的目标是让$$D(x)$$趋近于1.
第二个场景， 生成器的输入是隐变量$$z$$， 此隐变量根据模型的一个先验分布进行随机采样。 然后， 生成器生成的伪样本$$G(z)$$被输入判别器中。 在这个场景中， 两个玩家都在参与。 判别器试图让$$D(G(z))$$趋近于0， 生成器试图让其趋近于1. 如果两个模型具备足够的能力，那么最终游戏将达到纳什均衡， 也就是$$G(z)$$的生成样本将符合训练数据的分布， 并且对所有的$$x$$, $$D(x)=1/2$$.

形式上， GAN是结构化概率模型包含隐变量$$z$$以及观测变量$$x$$. （参考Goodfellow et al, (2016) 第16章关于结构化概率模型的介绍） 图13展示了图结构。

![Figure 13](/images/201705/03/fig13.jpg)

图13： GAN的图形化模型结构， 类似于VAEs， sparse coding, 等等。 它是一种直接的图像化模型也就是每一个隐变量影响每一个观测变量。 有些GAN变种去除了一些链接。

两个玩家被描述为两个函数， 每一个对输入和参数都是可微的。 判别器是函数$$D$$， 输入是$$x$$, 参数$$\theta^{(D)}$$。 生成器被定义为函数$$G$$, 输入$$z$$, 参数$$\theta^{(G)}$$。

两个玩家的损失函数都对应着各自的参数。 判别器希望最小化 $$J^{(D)}(\theta^{(D)},\theta^{(G)})$$但是只能通过对$$\theta^{(D)}$$的控制完成。 同样的生成器希望最小化$$J^{(D)}(\theta^{(D)},\theta^{(G)})$$但是只能通过对$$\theta^{(G)}$$的控制完成。
两个玩家的损失函数都受另一个玩家的参数影响， 但是却不能控制对方的参数， 这个场景像是一个游戏而不是一个优化问题。
此优化问题的解是一个（局部）最小化问题， 也就是一个参数空间的点其近旁的点都有比其大或者相等的损失。
这是游戏的纳什均衡。 这里我们使用术语局部微分纳什均衡(Ratliff et al., 2013)。
纳什均衡是一个元组$$(\theta^{(D)},\theta^{(G)})$$， 对参数$$\theta^{(D)}$$局部最小化$$J^{(D)}$$， 对参数$$\theta^{(G)}$$局部最小化$$J^{(G)}$$.

**生成器** 生成器是一个简单的可微函数$$G$$。 $$z$$根据一个简单的先验分布来采样， $$G(z)$$根据$$p_{model}$$生成样本$$x$$。
通常， $$G$$使用深度神经网络模型。 $$G$$的输入不一定非要对应着第一层， 输入可能被提供到任何的网络层中。 比如说， 我们可以将$$z$$ 分为两个向量， $$z^{(1)}$$, $$z^{(2)}$$, 然后$$z^{(1)}$$可以作为第一层的输入， $$z^{(2)}$$作为最后一层的输入。 **如果$$z^{(2)}$$是高斯分布的，那么$$x$$就是一个根据$$z^{(1)}$$的条件高斯分布**。 另一个流行的策略是将额外的或者相乘噪音加入到隐含层中，或则将噪音与网络的隐含层进行连接使用。 总之，我们可以看到生成器网络的设计有很少的限制。 如果我们希望$$p_{model}$$完全的支持$$x$$空间，那么我们需要$$z$$的维数至少要和$$x$$一样大, 并且$$G$$是可微的， 这是所有的设计条件。 
特别是， 任何的非线性ICA方法可以使用的模型都可以作为GAN的生成器网络。 GAN与微分autoencoder的关系相对比较复杂的； GAN可以训练的一些模型，VAE不能， 反之也一样。 但是这两个架构也有很大的交叉。 最大的不同是，当使用标准的反向传递优化时， VAE不能使用离散变量作为输入， 但是GAN不能有离散变量的输出。

**训练过程**
训练过程包含同步SGD。 每一步， 两个minibatch被采样： 一个是$$x$$来自训练数据，另一个是$$z$$的值来自模型的隐变量先验。
然后两个求导过程被同时执行： 一个是更新$$\theta^{(D)}$$来最小化$$J_{(D)}$$, 另一个是更新$$\theta^{(G)}$$来最小化$$J_{(G)}$$。
在这两个情况下， 你可以使用基于求导的优化算法。 Adam是一个好的选择。 很多作者推荐对其中一个玩家进行更多步的优化。 但是直到2016年底， 作者的意见是，实际应用中运行的比较好的方案是， 使用同步梯度下降，并对每一个玩家进行一步优化。


## 3.2 损失函数

有很多不同的损失函数可以被用于GAN。


### 3.2.1 判别器的损失函数, $$J_{(D)}$$

很多不同的GAN相关的工作，都使用相同的判别器损失函数， $$J_{(D)}$$。 区别之处是使用了不同的生成器的损失函数，$$J_{(G)}$$。
判别器的损失函数被定义为：

![Equation 8](/images/201705/03/eq08.jpg)

这是一个标准的交叉熵损失函数， 此函数使用sigmoid的输出。 通过训练一个标准的两类分类问题来最小化损失函数。 不同之处是此分类器被训练使用两个minibatch的数据； 一个来自训练数据， 对应标签1， 另一个来自生成器，对应标签0.

所有GAN的版本鼓励判别器来最小化方程式8. 在所有的情况下， 判别器有相同的优化策略。 **读者可以去完成7.1章的练习，答案在8.1章。 这个练习让我们了解如何得到最优的判别器优化策略， 并且讨论了此策略构成的重要性。**

通过训练判别器， 我们可以获得一个对每一个$$x$$一个比值的估计。 

![Equation 9](/images/201705/03/eq09.jpg)

估计这个比值使我们计算一个足够多样的方差和其导数。 此种优化是让GAN区别于变分autoencoder和玻尔兹曼机的主要点。
其他的深度生成模型基于下边界或者马尔可夫链来优化； GAN使用监督学习优化来估计两个密度的比值。 
GAN优化收到监督学习过拟合和训练不足问题的影响。
理论上， 通过完美的优化和使用足够多的数据可以克服此问题。 使用其他优化方法的其他的生产模型也有他们自身的一些问题。

使用游戏理论工具对GAN进行分析显得更加的自然， 我们称GAN为“对抗的”。 但是我们也可以认为他们是合作的， 在这种情况下，判别器估计密度的比例， 然后可以自由的与生成器分析这些信息。 从这一点上看， 判别器更像一个老师指导生成器如何提高自己并且超过对手。 当然，合作的观点没有在数学表达上有任何改变。


### 3.2.2 Minimax 最小最大化

到目前为止，我们详述了判别器的损失函数。 描述完整的游戏规格需要详述生成器的损失函数。

此游戏的最简单的版本是零和游戏， 也就是所有玩家的损失之和永远是零， 此游戏可以描述为：

![Equation 10](/images/201705/03/eq10.jpg)

因为$$J^{(G)}$$直接与$$J^{(D)}$$绑定， 我们整理完整的游戏通过一个价值函数详述判别器的报酬：

![Equation 11](/images/201705/03/eq11.jpg)

零和游戏经常被称为最小最大化游戏，因为这个方案包含最小化在外循环，最大化在内循环：

![Equation 12](/images/201705/03/eq12.jpg)

最小最大游戏最受关注是因为他在理论上容易控制。 Goodfellow et al. (2014b) 使用了GAN游戏的一个变形来展示了这个游戏的学习类似于最小化数据和模型的分布的Jensen-Shannon方差， 以及此游戏可以收敛到均衡， 只要两个玩家的策略可以在函数空间被直接更新。 在实际应用中， 玩家被表达为深度神经网络， 并且参数参数空间被更新， 所以，一些基于凸面的问题，不在此列。


### 3.2.3 启发式， 非饱和游戏

游戏中生成器使用的损失函数（方程式10）在理论分析的有用，但是在实际应用中表现并不好。

最小化正确目标类和分类器预测分布的交叉熵是很有效的， 因为损失函数从来不会达到饱和只要分类器还有错误的输出。
损失最终将饱和， 也就是趋近于零， 但是只有在分类器能够进行正确分类的情况下。

在最小最大游戏中， 判别器最小化交叉熵， 但是生成器最大化同一个交叉熵。 这对生成器来说很不幸， 因为当判别器能够以高的信心成功拒绝生成样本时， 生成器的导数将会消失。

为了解决此问题， 一个方式是继续对生成器使用交叉熵最小化。 
我们使用目标来构建交叉熵损失， 而不是使用判别器的损失来获取生成器的损失。 所以生成器的损失函数变为：

![Equation 13](/images/201705/03/eq13.jpg)

在最小化最大化游戏中， 生成器最小化判别器的对数概率为真。 在此游戏中， 生成器最大化判别器的对数概率为错误。

这个版本的游戏是收到启发式的启发， 而不是收到理论内容的启发。  
此游戏版本的唯一动机是保证每一个玩家有一个稳定的导数， 当玩家面临失败时。

此游戏版本， 游戏不再是零和， 并且不能使用一个单一值的函数来描述。

### 3.2.4 最大似然游戏

我们可能喜欢使用最大似然方法来优化GAN， 这样意味着最小化数据和模型分布的KL方差， 如方程式4. 
另外，在第二章， 我们说过GAN可以被故意的使用最大似然来处理， 为了简化与其他方法的比较。

有很多的方法可以优化方程式4， 使用GAN的框架。 Goodfellow （2014） 展示了使用：

![Equation 14](/images/201705/03/eq14.jpg)

$$\delta$$ 是逻辑sigmoid函数， 相等于最小化方程式4， 基于判别器最优假设。
此等价保持了预期； 在实际应用中， KL方差的随机梯度下降以及GAN训练过程都让真的期望导数有一些变动， 因为我们使用采样来估计导数（也就是$$x$$为了最大似然， $$z$$为了GAN）。 
这个等价是7.3章的一个练习。

其他的关于GAN的最大似然的近似方法也是可能的， 比如说Nowozin et al. (2016).


### 3.2.5 

![Figure 14](/images/201705/03/fig14.jpg)

### 3.2.6 损失函数比较

## 3.3 DCGAN结构

## 3.4 



注： 
1. 可微函数： 在微积分学中，可微函数是指那些在定义域中所有点都存在导数的函数。
