---
title: GAN介绍 - GAN是如何工作的?
layout: post
mathjax: true
---

[制作中]

我们已经了解了GAN与其他生成模型的区别，下面我们将学习GAN是如何工作的。

## 3.1 GAN framework

GAN的基本思想是两个玩家共同玩一个游戏。 其中一个叫生成器。 生成器根据训练数据的分布来生成样本。 另一个玩家是判别器。 判别器用来判别样本的真伪。
判别器使用传统的监督学习的方法，将输入分类为真和假两个类。 生成器被优化来试图欺骗判别器。
举个例子来说， 生成器类似于假币制造者，他试图制作假币， 判别器类似于警察， 他试图判别真币和假币。 
为了在游戏中取得成功， 造假者必须学习制造能够以假乱真的假币， 意味着生成器必须学习生成与训练数据有同样分布的样本。
图12展示了这个过程。

![Figure 12](/images/201705/03/fig12.jpg)

图12： GAN设计为两个对抗的玩家在同一个游戏中互相对抗。 玩家被描述为由一组参数组成的可微函数。 通常情况下，这些函数都使用深度神经网络。
这个游戏可以被展开为两个场景。 第一个场景， 随机的从训练数据集中采样$$x$$, 采样的数据作为判别器$$D$$的输入。 判别器的目的是预测样本是真实样本的概率， 此判决假设输入的样本一半是真样本，另一半是伪样本。 在此场景中， 判别器的目标是让$$D(x)$$趋近于1.
第二个场景， 生成器的输入是隐变量$$z$$， 此隐变量根据模型的一个先验分布进行随机采样。 然后， 生成器生成的伪样本$$G(z)$$被输入判别器中。 在这个场景中， 两个玩家都在参与。 判别器试图让$$D(G(z))$$趋近于0， 生成器试图让其趋近于1. 如果两个模型具备足够的能力，那么最终游戏将达到纳什均衡， 也就是$$G(z)$$的生成样本将符合训练数据的分布， 并且对所有的$$x$$, $$D(x)=1/2$$.

形式上， GAN是结构化概率模型包含隐变量$$z$$以及观测变量$$x$$. （参考Goodfellow et al, (2016) 第16章关于结构化概率模型的介绍） 图13展示了图结构。

![Figure 13](/images/201705/03/fig13.jpg)

图13： GAN的图形化模型结构， 类似于VAEs， sparse coding, 等等。 它是一种直接的图像化模型也就是每一个隐变量影响每一个观测变量。 有些GAN变种去除了一些链接。

两个玩家被描述为两个函数， 每一个对输入和参数都是可微的。 判别器是函数$$D$$， 输入是$$x$$, 参数$$\theta^{(D)}$$。 生成器被定义为函数$$G$$, 输入$$z$$, 参数$$\theta^{(G)}$$。

两个玩家的损失函数都对应着各自的参数。 判别器希望最小化 $$J^{(D)}(\theta^{(D)},\theta^{(G)})$$但是只能通过对$$\theta^{(D)}$$的控制完成。 同样的生成器希望最小化$$J^{(D)}(\theta^{(D)},\theta^{(G)})$$但是只能通过对$$\theta^{(G)}$$的控制完成。
两个玩家的损失函数都受另一个玩家的参数影响， 但是却不能控制对方的参数， 这个场景像是一个游戏而不是一个优化问题。
此优化问题的解是一个（局部）最小化问题， 也就是一个参数空间的点其近旁的点都有比其大或者相等的损失。
这是游戏的纳什均衡。 这里我们使用术语局部微分纳什均衡(Ratliff et al., 2013)。
纳什均衡是一个元组$$(\theta^{(D)},\theta^{(G)})$$， 对参数$$\theta^{(D)}$$局部最小化$$J^{(D)}$$， 对参数$$\theta^{(G)}$$局部最小化$$J^{(G)}$$.

**生成器** 生成器是一个简单的可微函数$$G$$。 $$z$$根据一个简单的先验分布来采样， $$G(z)$$根据$$p_{model}$$生成样本$$x$$。
通常， $$G$$使用深度神经网络模型。 $$G$$的输入不一定非要对应着第一层， 输入可能被提供到任何的网络层中。 比如说， 我们可以将$$z$$ 分为两个向量， $$z^{(1)}$$, $$z^{(2)}$$, 然后$$z^{(1)}$$可以作为第一层的输入， $$z^{(2)}$$作为最后一层的输入。 **如果$$z^{(2)}$$是高斯分布的，那么$$x$$就是一个根据$$z^{(1)}$$的条件高斯分布**。 另一个流行的策略是将额外的或者相乘噪音加入到隐含层中，或则将噪音与网络的隐含层进行连接使用。 总之，我们可以看到生成器网络的设计有很少的限制。 如果我们希望$$p_{model}$$完全的支持$$x$$空间，那么我们需要$$z$$的维数至少要和$$x$$一样大, 并且$$G$$是可微的， 这是所有的设计条件。 
特别是， 任何的非线性ICA方法可以使用的模型都可以作为GAN的生成器网络。 GAN与微分autoencoder的关系相对比较复杂的； GAN可以训练的一些模型，VAE不能， 反之也一样。 但是这两个架构也有很大的交叉。 最大的不同是，当使用标准的反向传递优化时， VAE不能使用离散变量作为输入， 但是GAN不能有离散变量的输出。

**训练过程**
训练过程包含同步SGD。 每一步， 两个minibatch被采样： 一个是$$x$$来自训练数据，另一个是$$z$$的值来自模型的隐变量先验。
然后两个求导过程被同时执行： 一个是更新$$\theta^{(D)}$$来最小化$$J_{(D)}$$, 另一个是更新$$\theta^{(G)}$$来最小化$$J_{(G)}$$。
在这两个情况下， 你可以使用基于求导的优化算法。 Adam是一个好的选择。 很多作者推荐对其中一个玩家进行更多步的优化。 但是直到2016年底， 作者的意见是，实际应用中运行的比较好的方案是， 使用同步梯度下降，并对每一个玩家进行一步优化。


## 3.2 损失函数

有很多不同的损失函数可以被用于GAN。


### 3.2.1 判别器的损失函数, $$J_{(D)}$$

很多不同的GAN相关的工作，都使用相同的判别器损失函数， $$J_{(D)}$$。 区别之处是使用了不同的生成器的损失函数，$$J_{(G)}$$。
判别器的损失函数被定义为：

![Equation 8](/images/201705/03/eq08.jpg)

这是一个标准的交叉熵损失函数， 此函数使用sigmoid的输出。 通过训练一个标准的两类分类问题来最小化损失函数。 不同之处是此分类器被训练使用两个minibatch的数据； 一个来自训练数据， 对应标签1， 另一个来自生成器，对应标签0.

所有GAN的版本鼓励判别器来最小化方程式8. 在所有的情况下， 判别器有相同的优化策略。 **读者可以去完成7.1章的练习，答案在8.1章。 这个练习让我们了解如何得到最优的判别器优化策略， 并且讨论了此策略构成的重要性。**

通过训练判别器， 我们可以获得一个对每一个$$x$$一个比值的估计。 

![Equation 9](/images/201705/03/eq09.jpg)

估计这个比值使我们计算一个足够多样的方差和其导数。 此种优化是让GAN区别于变分autoencoder和玻尔兹曼机的主要点。
其他的深度生成模型基于下边界或者马尔可夫链来优化； GAN使用监督学习优化来估计两个密度的比值。 
GAN优化收到监督学习过拟合和训练不足问题的影响。
理论上， 通过完美的优化和使用足够多的数据可以克服此问题。 使用其他优化方法的其他的生产模型也有他们自身的一些问题。

使用游戏理论工具对GAN进行分析显得更加的自然， 我们称GAN为“对抗的”。 但是我们也可以认为他们是合作的， 在这种情况下，判别器估计密度的比例， 然后可以自由的与生成器分析这些信息。 从这一点上看， 判别器更像一个老师指导生成器如何提高自己并且超过对手。 当然，合作的观点没有在数学表达上有任何改变。


### 3.2.2 Minimax 最小最大化

到目前为止，我们详述了判别器的损失函数。 描述完整的游戏规格需要详述生成器的损失函数。

此游戏的最简单的版本是零和游戏， 也就是所有玩家的损失之和永远是零， 此游戏可以描述为：

![Equation 10](/images/201705/03/eq10.jpg)

因为$$J^{(G)}$$直接与$$J^{(D)}$$绑定， 我们整理完整的游戏通过一个价值函数详述判别器的报酬：

![Equation 11](/images/201705/03/eq11.jpg)

零和游戏经常被称为最小最大化游戏，因为这个方案包含最小化在外循环，最大化在内循环：

![Equation 12](/images/201705/03/eq12.jpg)

最小最大游戏最受关注是因为他在理论上容易控制。 Goodfellow et al. (2014b) 使用了GAN游戏的一个变形来展示了这个游戏的学习类似于最小化数据和模型的分布的Jensen-Shannon方差， 以及此游戏可以收敛到均衡， 只要两个玩家的策略可以在函数空间被直接更新。 在实际应用中， 玩家被表达为深度神经网络， 并且参数参数空间被更新， 所以，一些基于凸面的问题，不在此列。


### 3.2.3 启发式， 非饱和游戏

游戏中生成器使用的损失函数（方程式10）在理论分析的有用，但是在实际应用中表现并不好。

最小化正确目标类和分类器预测分布的交叉熵是很有效的， 因为损失函数从来不会达到饱和只要分类器还有错误的输出。
损失最终将饱和， 也就是趋近于零， 但是只有在分类器能够进行正确分类的情况下。

在最小最大游戏中， 判别器最小化交叉熵， 但是生成器最大化同一个交叉熵。 这对生成器来说很不幸， 因为当判别器能够以高的信心成功拒绝生成样本时， 生成器的导数将会消失。

为了解决此问题， 一个方式是继续对生成器使用交叉熵最小化。 
我们使用目标来构建交叉熵损失， 而不是使用判别器的损失来获取生成器的损失。 所以生成器的损失函数变为：

![Equation 13](/images/201705/03/eq13.jpg)

在最小化最大化游戏中， 生成器最小化判别器的对数概率为真。 在此游戏中， 生成器最大化判别器的对数概率为错误。

这个版本的游戏是收到启发式的启发， 而不是收到理论内容的启发。  
此游戏版本的唯一动机是保证每一个玩家有一个稳定的导数， 当玩家面临失败时。

此游戏版本， 游戏不再是零和， 并且不能使用一个单一值的函数来描述。

### 3.2.4 最大似然游戏

我们可能喜欢使用最大似然方法来优化GAN， 这样意味着最小化数据和模型分布的KL方差， 如方程式4. 
另外，在第二章， 我们说过GAN可以被故意的使用最大似然来处理， 为了简化与其他方法的比较。

有很多的方法可以优化方程式4， 使用GAN的框架。 Goodfellow （2014） 展示了使用：

![Equation 14](/images/201705/03/eq14.jpg)

$$\delta$$ 是逻辑sigmoid函数， 相等于最小化方程式4， 基于判别器最优假设。
此等价保持了预期； 在实际应用中， KL方差的随机梯度下降以及GAN训练过程都让真的期望导数有一些变动， 因为我们使用采样来估计导数（也就是$$x$$为了最大似然， $$z$$为了GAN）。 
这个等价是7.3章的一个练习。

其他的关于GAN的最大似然的近似方法也是可能的， 比如说Nowozin et al. (2016).


### 3.2.5 方差选择是否是GAN的可区分特征

作为我们调查GAN是如何工作的一部分， 我们可能好奇是什么让他在生成图片任务中表现的如此的好。

以前， 很多人（包括作者本人）相信GAN提供了锐化， 显式的样本，是因为他们最小Jensen-Shannon方差， 但是VAE产生模糊的样本因为他们最小化数据和模型的KL方差。

KL方差不是对称的； 最小化$$D_{KL}(p_{model}||p_{data})$$与最小化$$D_{KL}(p_{data}||p_{model})$$。 最大似然估计执行的是前者， 最小化Jensen-Shannon方差更像是优化后者。 
如图14所示， 后者可能会生成更好的样本， 因为使用此方差训练的模型更倾向于生成符合训练数据分布的样本， 即便是忽略了一些模式， 而不是包括所有的模式 但是生成的样本却不符合任何训练集的模式。

![Figure 14](/images/201705/03/fig14.jpg)

图14： KL方差的两个表达不是等价的。 最明显的不同是当模型拟合数据分布的能力很差时。
这里展示了一个一维数据$$x$$分布的例子。 在这个例子中， 数据分布是两个混合的高斯分布的组合， 模型使用一个单一的高斯模型。 因为一个单一的高斯分布不能准确的表达真实的数据分布， 方差的选择将决定模型选择。
左边的图使用了最大似然测度。 此模型选择对这两个模式进行平均处理， 因此它侧重于对两者整体的概率最大化。 右边的图， 使用反向顺序的KL方差。 我们可以认为$$D_{KL}(p_{data}||p_{model})$$倾向于对所有数据分布的整体都提高概率， $$D_{KL}(p_{model}||p_{data})$$侧重于降低数据不存在区域的概率。 此种视角， 使我们期待$$D_{KL}(p_{model}||p_{data})$$产生更好看的样本，因为模型将不会选择产生分布在数据的两种模式之间的非正常样本。

一些新的证据建议使用Jensen-Shannon方差不能解释为什么GAN会产生锐化的样本：

* 现在可能来训练GAN使用最大似然， 如3.2.4章描述的。 这些模型仍然可能生成锐化样本， 并且可以选择一个小数量的模式。 如图15。

  ![Figure 15](/images/201705/03/fig15.jpg)
  
  图15： f-GAN模型能够最小化很多不同的方差。 因为模型被训练最小化$$D_{KL}(p_{data}||p_{model})$$并且仍然可以产生锐化的样本， 并且倾向于选择少量的模式， 我们可以总结为使用Jensen-Shannon方差不是一个GAN特别重要的不同特征， 并且它也不能介绍为什么GAN的样本会倾向于锐化。

* GAN经常可以通过使用很少的模式就可以生成数据； 少于模型能力限制的影响。 反向KL倾向于使用模型可以做到的尽可能多的模式来生成数据。 这说明模式被摧毁是通过一个因素而不是通过方差选择。

总之， 这说明GAN选择少量的模式生成数据， 因为训练过程的缺点， 而不是因为他们想要最小化的方差。 我们将在第5.1.1章中进一步介绍。
GAN产生锐化图像的原因还没有完全的明确。 可能是因为使用GAN训练的这类模型与使用VAE训练的模型不同 （比如， 使用GAN比使用高斯更容易构建模式， 当x有一个更加复杂的分布时）。
也可能是因为GAN的近似处理与其他方法的近似有不同的影响。

### 3.2.6 损失函数比较

我们可以认为生成器网络是通过一些特殊的增强学习来训练的。 
与其说一个特定的输出$$x$$应该对应一个$$z$$， 生成器采取一些行动，并且根据接收这些行动来带来的反馈（奖励）。
特别是， $$J^{(G)}$$根本不直接参考训练数据； 所有的关于训练数据的的信息都是仅仅通过判别器反馈的信息来进行学习。 （附带的， 这将使得GAN更不容易过拟合， 因为生成器不会直接的复制训练数据。）
其学习过程与传统的增强学习不一样， 这是因为：

* 生成器不仅可以观察报酬函数的输出，并且可以获得它的导数。
* 报酬函数是非稳定的； 报酬是通过判别器对生成器策略改变的反应来获取的。

在所有情况下， 我们可以认为采样过程开始于选择一个特定的$$z$$, 然后作为一个独立的过程来接受一个单一的报酬， 也就是说不其他的$$z$$相关的行为无关。
给生成器的反馈是一个标量函数，D（G（z））。 
我通常认为这与损失有关（负的报酬）。
生成器的损失总是单调下降的， 对于D（G(z)）， 但是不同的游戏被设计为来使损失沿着不同的曲线下降的更快。

图16展示了三个GAN的不同变种的反馈的损失的曲线对应不同的$$D(G(z))$$。
我们可以看到， 最大似然方法的损失函数有很高的方差里， 因为有很少的样本属于真而非假，导致了多数的损失的导数。
启发式非饱和的损失函数有很低的样本方差， 这可以解释为什么为什么在实际应用中很成功。
这告诉我们减少方差的技术是提高GAN表现的很重要的研究领域， 特别是基于最大似然的GAN。

![Figure 16](/images/201705/03/fig16.jpg)

图16： 生成器接受的关于样本$$G(z)$$的损失只取决于判别器对此样本的反馈。 判别器将其识别为真样本的概率越高，那么生成器接受到的损失就越小。 我们可以看到当样本更像假样本时， minmax和最大似然都会有一个很小的导数， 我们可以看到左边是很平坦的曲线。
启发式非饱和方法避免了此问题。 最大似然还受到绝大多数导数值只是来自于很少的样本，如右边的曲线， 这意味着很少的样本影响了minibatch的导数计算。 
这告诉我们减少方差的技术是提供GAN表现的很重的研究领域， 特别是基于最大似然的GAN。 

## 3.3 DCGAN结构

今天多数的GAN很多都基于DCGAN的结构 （Radford et al., 2015）。
DCGAN基于“深度，卷积GAN”， 尽管在DCGAN以前，GAN也使用深度并且卷积网络的， DCGAN的用途是指这个特别的样式的结构。
DCGAN结构的一些主要的观点有：

* 在判别器和生成器的多数层中都使用Batch标准化(Ioffe and Szegedy, 2015)， 判别器的两个minibatch被粉笔的标准化。 生成器的最后层和第一层没有被标准化， 因此模型可以学习正确的平均，以及对数据分布的调整比例。 看图17.
* 整体网络结构借鉴了（Springenberg et al., 2015）。 这个结构即包含pooling 也包含unpooling层。 当生成器需要提高空间维度时， 它使用转置卷积，使用stride大于1.
* 使用Ada优化器，而不是SGD和冲量。

![Figure 17](/images/201705/03/fig17.jpg)

图17： DCGAN使用的生成器网络。 图来自Radford et al. (2015).

在DCGAN以前， LAPGAN（Denton et al., 2015）是唯一GAN版本可以处理高分辨率图像的。LAPGAN需要一个多阶段的生成过程， 多个GAN生成多个不同层次的， 拉普拉斯金字塔来表达图像的细节。 DCGAN是第一个使用a single shot的方式来生成高分辨率图像GAN模型。 如图18所示， 当限制图像的类别时DCGAN可以生成很高质量的图像， 比如说卧室图像。 DCGAN也清晰的展示了， GAN学习通过有意义的方式来使用隐代码， 如图19所示， 在潜在空间的简单的算术操作有明确解释，此解释可以与输入信息的语义属性的算术操作相对应。 

![Figure 18](/images/201705/03/fig18.jpg)

图18： DCGAN生成的一些卧室图像， 使用LSUN数据集训练。

![Figure 19](/images/201705/03/fig19.jpg)

图19： DCGAN展示了GAN可以学习分布式表征，也就是可以区别性别信息和戴眼镜的信息。 如果我们有一个戴眼镜的男人的向量， 然后减去用来表达不带眼镜男人的向量， 最后加上表达不戴眼镜女人的向量， 我们就可以得到一个戴眼镜女人的向量。 生成模型可以正确的解码所有哪些属于正确类别的这种表达的向量生成图像。 图片来自Radford et al. (2015).

## 3.4 GAN与噪音对比估计和最大似然的关系

当我们试图去理解GAN是如何工作的， 我们可能想知道他与噪音对比估计的联系（NCE） （Gutmann and Hyvarinen, 2010）。
Minimax GAN使用来自NCE的损失函数作为他们的价值函数， 因此这两个方法好像很相近。 但实际上，他们学习非常不同的事情， 因为这两个方法针对的是游戏中不同的玩家。 简单的说， NCE的目标是学习判别器的密度模型， 但是GAN的目标是学习采样器来定义生成器。
但是这两个任务看起来在本质上是很相近的， 两个任务的导数实际上也很不相同。 惊奇的是，最大似然与NCE很相似， 并且对应着与minimax游戏有意义的价值函数， 但是使用了一系列的启发式更新的策略而不是梯度下降对任何一个玩家。 图20总结了他们的关系。

![Figure 20](/images/201705/03/fig20.jpg)

图20： Goodfellow（2014）展示了NCE,MLE,GAN的关系： 所有三种方法可以被解释为训练minimax游戏的策略，使用一样的价值函数。
最大的不同是$$p_{model}$$的分布。 对GAN来说， 生成器是p_{model}, 但是， NCE, MLE是指判别器。 除了这些， 还有更新策略的不同。 GAN学习两个玩家通过梯度下降。 MLE学习判别器也是使用梯度下降， 但是它为生成器有一个启发式的更新规则。 特别是， 在每一次判别器更新步骤以后， MLE复制学习的判别器的密度模型， 并且转换为一个采样器并将其用作生成器。 NCE从来不更新生成器； 他使用一个固定的噪音。

注： 
1. 可微函数： 在微积分学中，可微函数是指那些在定义域中所有点都存在导数的函数。
