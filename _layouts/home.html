---
layout: default
---

<div class="home">
  <h1 class="page-heading"><b>Peng Shen(沈 鵬)</b></h1>
  <ul class="post-list">
    <li>
      I am a researcher at NICT, Kyoto, Japan, on automatic speech recognition, deep learning technology, spoken language identification, speaker recognition, event detection, etc.
      I have four years full-time system development experience as a system engineer.
    </li>
  </ul>
 
  <h1 class="page-heading"><b>Research interest</b></h1>
  <ul class="post-list">
    <li>
      Automatic speech recognition, signal processing, and machine learning (deep learning) related to image processing, data analysis and natural language processing.
    </li>
  </ul>    

  <h1 class="page-heading"><b>Work experiences</b></h1>
  <ul class="post-list">
    <li>
   2014-Present: Researcher at National Institute of Information and Communications Technology (NICT). <br>
   2004-2007: Information Management Engineer at Lenovo Group, China. <br>
   2007-2013: MA, Ph. D. in , at Electronics and Information system Engineering, Gifu University, Japan. <br>
    </li>
  </ul>    
  

  <h1 class="page-heading"><b>Awards & Certifications</b></h1>
  <ul class="post-list">
    <li>
    2015.07: Japanese-Language Proficiency Test N1. <br>
    2015.04: NICT team award.<br>
    2014.12: Won the 1st position among the 8 international teams (IWSLT TED ASR evaluation).<br>
    2006.09: Lenovo R&D award of excellence.<br>
    2003.12: Award of excellence (ZCDL Co. Ltd.). <br>
    </li>
  </ul>      


  <h1 class="page-heading"><b>Publications</b></h1>
  <ul class="post-list">
    <li>
      <h4><b>Journals (Peer reviewed)</b></h4>
      <p>
        <li>
          Regularization of neural network model with distance metric learning for i-vector based spoken language identification <br>
					Xugang Lu, <u><b>Peng Shen</b></u>, Yu Tsao, Hisashi Kawai<br>
					In Computer Speech and Language, vol. 44, pp. 48–60, July 2017.<br>
				</li>
					
        <li>
					Combination of multiple acoustic models with unsupervised adaptation for lecture speech transcription <br>				
					<u><b>Peng Shen</b></u>, Xugang Lu, Xinhui Hu, Naoyuki Kanda, Masahiro Saiko, Chiori Hori, Hisashi Kawai<br>
					In Speech Communication, vol.82, pp. 1-13, Sep, 2016.<br>
			  </li>
					
					
        <li>
					Multi-Stream Sparse Representation Features for Noise Robust Audio-Visual Speech Recognition<br>
					<u><b>Peng Shen</b></u>, Satoshi Tamura and Satoru Hayamizu<br>
					In journal of Acoustical Science and Technology, vol.35, no.1, 2014.<br>
			  </li>
      </p>
                    
      <h4><b>International Conferences (Peer reviewed)</b></h4>
      <p>
				<li>
					Incremental training and construction the very deep convolutional residual network acoustic models<br>
					Sheng Li, Xugang Lu, <u><b>Peng Shen</b></u>, Ryoichi Takashima, Tatsuya Kawahara and Hisashi Kawai<br>
					In Proc. ASRU, Okinawa, Japan, 16-20, Dec. 2017.<br>
				</li>					
					
					
        <li>
					Conditional Generative Adversarial Nets Classifier for Spoken Language Identification <br>
					<u><b>Peng Shen</b></u>, Xugang Lu, Sheng Li, Hisashi Kawai <br>
					In Proc. Interspeech, Stochholm, Sweden, Aug. 20-24, 2017. <br>
				</li>
					
        <li>					
					Comparison of Regularization Constraints in Deep Neural Network based Speaker Adaptation <br>
					<u><b>Peng Shen</b></u>, Xugang Lu, Hisashi Kawai <br>
					In The 10th International Symposium on Chinese Spoken Language Processing, Oct. 2016.<br><br>
				</li>
					
        <li>
					"Automatic acoustic segmentation in N-best list rescoring for lecture speech recognition"<br>
					<u><b>Peng Shen</b></u>, Xugang Lu, Hisashi Kawai,  <br>
					in The 9th International Symposium on Chinese Spoken Language Processing, Oct. 2016.<br>
				</li>
					
        <li>
					A Pseudo-task Design in Multi-task Learning Deep Neural Network for Speaker Recognition<br>
					Xugang Lu, <u><b>Peng Shen</b></u>, Hisashi Kawai<br>
					In The 9th International Symposium on Chinese Spoken Language Processing, Oct. 2016.<br>
				</li>
					
        <li>
					Pair-wise Distance Metric Learning of Neural Network Model for Spoken Language Identification<br>
					Xugang Lu, <u><b>Peng Shen</b></u>, Yu Tsao, and Hisashi Kawai<br>
					In Proc. Interspeech, Sep. 2016.<br>
				</li>
					
        <li>
					Local fisher discriminant analysis for spoken language identification<br>
					<u><b>Peng Shen</b></u>, Xugang Lu, Lemao Liu and Hisashi Kawai<br>
					In Proc. ICASSP, Mar. 2016.<br>
				</li>
					
        <li>
          Sparse representation with temporal max-smoothing for acoustic event detection<br>
					Xugang Lu, <u><b>Peng Shen</b></u>, Yu Tsao, Chiori Hori and Hisashi Kawai<br>
					In Proc. Interspeech, pp. 1176-1180, Sep. 2015.<br>
				</li>
					
        <li>
          The NICT ASR System for IWSLT 2014<br>
					<u><b>Peng Shen</b></u>, Xugang Lu, Xinhui Hu, Naoyuki Kanda, Masahiro Saiko, Chiori Hori<br>
					In International Workshop on Spoken Language Translation (IWSLT), Lake Tahoe, USA, pp.113-118, Dec. 2014.<br>
				</li>
					
        <li>
					Spectral Patch Based Sparse Coding for Acoustic Event Detection<br>
					Xugang Lu, Yu Tsao, <u><b>Peng Shen</b></u>, Chiori Hori<br>
					In The 9th International Symposium on Chinese Spoken Language Processing (ISCSLP), Singapore, Set. 2014.<br>
				</li>
					
        <li>
					Audio-visual Interaction in Sparse Representation Features for Noise Robust Audio-visual Speech Recognition<br>
					<u><b>Peng Shen</b></u>, Satoshi Tamura and Satoru Hayamizu<br>
					In The 12th International Conference on Auditory-Visual Speech Processing(AVSP), Annecy, France, pp.43-48, Aug. 2013.<br>
				</li>
					
        <li>
					Feature Reconstruction using Sparse Imputation for Noise Robust Audio-Visual Speech Recognition<br>
					<u><b>Peng Shen</b></u>, Satoshi Tamura and Satoru Hayamizu<br>
					In Int. Conf. APSIPA ASC, USA, ps.5-sla.18, no.125, pp.1-4, Dec, 2012.<br>
				</li>
					
        <li>
					Evaluation of real-time audio-visual speech recognition<br>
					<u><b>Peng Shen</b></u>, Satoshi Tamura and Satoru Hayamizu<br>
					In The 9th International Conference on Auditory-Visual Speech Processing (AVSP), Hakone, Japan, pp.77-80, Oct. 2010.<br>
				</li>
					
      </p>

      <h4><b>Domestic Conferences</b></h4>
      <p>
        <li>
					Improving CTC-based acoustic model with very deep residual neural network<br>
					S. Li, X. Lu, R.Takashima, <u><b>P. Shen</b></u> and H. Kawai<br>
					In Acoustical Society of Japan, spring, 2018.<br>
			  </li>		
					
        <li>
					cGAN-classifier: Conditional Generative Adversarial Nets for Classification<br>
					<u><b>Peng Shen</b></u>, Xugang Lu, Sheng Li and Hisashi Kawai<br>
					In Acoustical Society of Japan, Set. 2017.<br>
				</li>
					
        <li>
					Very deep convolutional residual network acoustic models for Japanese lecture transcription<br>
					Sheng Li, Xugang Lu, <u><b>Peng Shen</b></u> and Hisashi Kawai<br>
					In Acoustical Society of Japan, Set. 2017.<br>
				</li>
                    
					
			  <li>
					Building WFST based Grapheme to Phoneme Conversion for Khmer<br>
					Kak Soky, Xugang Lu, <u><b>Peng Shen</b></u>, Hiroaki Kato, Hisashi Kawai, Chuon Vanna, Vichet Chea<br>
					In KNLP, 2016.<br>
        </li>

			  <li>
					Investigation on nonparametric discriminant analysis for language identification<br>
					<u><b>Peng Shen</b></u>, Xugang Lu and Hisashi Kawai<br>
					In 2016 Spring Meeting of Acoustical Society of Japan, Mar. 2016.<br>
        </li>
					
					
        <li>
					The 2014 NICT Automatic Speech Recognition System<br>
					<u><b>Peng Shen</b></u>, Xugang Lu, Xinhui Hu, Naoyuki Kanda, Masahiro Saiko, Chiori Hori<br>
					In 2015 Spring Meeting of Acoustical Society of Japan, 1-P-20, March, 2015.<br>
        </li>
					
        <li>
					Feature Reconstruction using Sparse Imputation for Noise Robust Audio-Visual Speech Recognition<br>
					<u><b>Peng Shen</b></u>, Satoshi Tamura and Satoru Hayamizu<br>
					In 2012 Autumn Meeting Acoustical Society of Japan, 3-P-8, pp.217-218, Set. 2012. (In Japanese)<br>
			  </li>
				
        <li>Recent efforts for high-performance multimodal speech recognition<br>
					Satoshi Tamura, <u><b>Peng Shen</b></u>, Hiroya Okuda, Naoya Ukai, Takuya Kawasaki, Takumi Seko, Satoru Hayamizu<br>
					In Technical Reports. Information Processing Society of Japan, vol.112, no.369, pp.41-46, Dec. 2012. (in Japanese)<br>
        </li>
					
        <li>
					Development of Real-time Audio-Visual Speech Recognition System<br>
					<u><b>Peng Shen</b></u>, Satoshi Tamura and Satoru Hayamizu<br>
					In 2010 Spring Meeting of Acoustical Society of Japan, 1-P-27, pp.217-218, March, 2010.<br>
        </li>
					
      </p>
      <h4><b>Book Translation</b></h4>
      <p>
        <li>
          NIPS 2016 Tutorial: Generative Adversarial Networks. <br> 
					&nbsp;&nbsp;<a href="https://sinpycn.github.io/category/gan-tutorial.html" target="_blank">(Translation: In Chinese)</a><br>
					&nbsp;&nbsp;<a href="https://arxiv.org/abs/1701.00160" target="_blank">(Original English Version: arXiv:1701.00160)</a>

        </li>
      </p>
  </ul>   
  


  
  <h1 class="page-heading">New Posts</h1>
  
  {{ content }}


    {% for post in site.posts %}
        {% assign date_format = site.minima.date_format | default: "%b %-d, %Y" %}
        <span class="post-meta">{{ post.date | date: date_format }}</span>
        <a class="post-link" href="{{ post.url | relative_url }}"><font size="4">{{ post.title | escape }}</font></a>
    {% endfor %}


  <!--<p class="rss-subscribe">subscribe <a href="{{ "/feed.xml" | relative_url }}">via RSS</a></p>-->

</div>
