
http://www.sohu.com/a/144843442_473283

实用的贝叶斯公式，在实践中GAN来进行无监督学习和半监督式学习。
在这一框架之下，使用了动态的梯度汉密尔顿蒙特卡洛（Hamiltonian Monte Carlo）来将生成网络和判别网络中的权重最大化。
其获得结果的方法非常的直接，并且在不需要任何标准的干预，比如特征匹配或者mini-batch discrimination的情况下，都获得了良好的表现。

通过对生成器中的参数部署一个具有表达性的后验机制（posteriors）。
贝叶斯GAN能够避免模式碰撞（mode-collapse），产生可判断的、多样化的候选样本，并且提供在既有的一些基准测试上，能够提供最好的半监督学习量化结果。
比如，SVHN, CelebA 和 CIFAR-10。效果远远超过 DCGAN, Wasserstein GANs 和 DCGAN 等等。


虽然GAN有着极大的影响力，但是他们的学习目标会导致模式碰撞（mode collapse），也就是，生成器只存储了少量的几个训练样本，来骗过判别器。
这种方法论是对过去的高斯混合中最大似然密度估计的一种“怀旧”：通过每一个组件的变化的碰撞，我们可以获得一些永久性的相似性，
然后把这些相似性储存在数据集中，但是，这些相似性对于可生成的密度估计来说是无用的。

此外，在GAN的训练过程中，需要有大量的干预，其中包括，特征匹配、标签梳理和mini-batch discrimination。
为了缓解这些在实践中的困难，最近许多研究都着眼于在标准的GAN训练中，用可转化的衡量标注，
比如f-fivergences和Wasserstein分歧来替换Jensen-Shannon 分歧。


https://arxiv.org/pdf/1705.09558.pdf
